# 路由規則管理指南

本文檔以繁體中文說明 **當資料透過 `batch_upload` 寫入 MongoDB 後，如何根據路由規則自動派送到分析節點並套用指定參數**。內容涵蓋整體資料流、前置設定、規則 JSON 結構、測試與疑難排解，協助維運人員快速掌握操作要點。

---

## 1. 整體資料流

1. **批次上傳**：`debug_tools/batch_upload` 工具把音訊及其 `info_features` 寫入指定的 MongoDB instance（欄位範本見 `debug_tools/batch_upload/CHANGES_SUMMARY.md`）。
2. **任務偵測**：`core/state_management/services/task_scheduler.py` 監看每個啟用的 MongoDB instance，輪詢 `info_features.upload_time`，一旦偵測到新記錄即讀取其 `info_features`。
3. **匹配規則**：調度器呼叫 `RoutingRule.find_matching_rules()`（來源：`core/state_management/models/routing_rule.py`）依優先級比對 `conditions`。
4. **建立任務**：對於每個命中的 `actions`，調度器組合任務 payload（分析方法、參數 config、目標 MongoDB instance等）並以 `analysis.<analysis_method_id>` 的 routing key 發送到 RabbitMQ（`core/state_management/utils/rabbitmq_handler.py`）。
5. **分析節點消費**：分析服務（例如 `a_sub_system/analysis_service_v2`）訂閱 `analysis.#` routing key，接收任務後依 `config_id` 讀取參數並執行實際分析。

---

## 2. 必備前置設定

- **MongoDB instance**：於 Web UI「MongoDB instance」或 `MongoDBInstance` API 建立連線資訊，確保資料來源與分析節點能共用。可在 `core/state_management/views/instance_views.py` 找到對應表單欄位。
- **RabbitMQ**：確認 `core/state_management/config.py` 的 `RABBITMQ_CONFIG`（或環境變數 `RABBITMQ_HOST/PORT/USERNAME/PASSWORD/...`）指向與分析節點相同的 RabbitMQ，交換器/佇列預設為 `analysis_tasks_exchange` / `analysis_tasks_queue`。
- **分析設定（AnalysisConfig）**：在「分析設定」頁面或 `/api/configs` 建立 `analysis_method_id` 與一組 JSON `parameters`，以定義模型路徑、特徵選項等。結構實作見 `core/state_management/models/analysis_config.py`。
- **批次上傳欄位**：確保上傳工具提供規則會使用到的 `info_features` 欄位，例如：
  - `dataset_UUID`, `device_id`, `label`, `machine_type`, `obj_ID`
  - 上傳時間 `info_features.upload_time`（由工具自動寫入）
  - 其他屬性如 `target_channel`, `sample_rate`, `mimii_metadata.fault_type` 等
- **任務調度服務**：啟動 `TaskScheduler`（可作為長駐服務或隨 Web UI 啟動）以確保新資料會被偵測並派送。

---

## 3. 路由規則資料結構

路由規則儲存在 `routing_rules` 集合，其主要欄位如下：

| 欄位                            | 說明                                                                                                               |
| ------------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| `rule_id`                     | 規則唯一識別碼（預設 UUID）。                                                                                      |
| `rule_name` / `description` | 顯示用名稱與說明。                                                                                                 |
| `priority`                    | 整數，數值越大代表越先匹配（僅影響規則排序，不再寫入 RabbitMQ routing key）。                                      |
| `conditions`                  | JSON 物件，用於比對 `info_features`；**可為空物件 `{}`，表示匹配所有資料**。支援單值、陣列與複雜運算子。 |
| `actions`                     | 陣列；每個元素對應一條將要建立的分析任務。                                                                         |
| `enabled`                     | 是否啟用。僅啟用規則會被 `TaskScheduler` 讀取。                                                                  |

### 3.1 `conditions` 語法

`RoutingRule.match()` 支援以下語法對 `info_features` 做比對：

| 型別       | 範例                                        | 說明                                                                             |
| ---------- | ------------------------------------------- | -------------------------------------------------------------------------------- |
| 精確匹配   | `"dataset_UUID": "mimii_batch_upload"`    | 欄位值需完全相等。                                                               |
| 多值匹配   | `"label": ["normal", "abnormal"]`         | 只要實際值在陣列中即命中。                                                       |
| 複合運算子 | `"duration": {"$gte": 5.0, "$lte": 15.0}` | 支援 `$eq`, `$ne`, `$gt`, `$gte`, `$lt`, `$lte`, `$in`, `$nin`。 |

若需要比對巢狀欄位，可直接以完整 key，例如 `"mimii_metadata.fault_type": "fan_fault"`。

> 若 `conditions` 為空物件 `{}`，則視為無條件匹配，所有新寫入的資料都會觸發該規則的 `actions`。

### 3.2 `actions` 結構

每個 action 需包含：

| 欄位                   | 說明                                                                               |
| ---------------------- | ---------------------------------------------------------------------------------- |
| `analysis_method_id` | 例如 `sliced_wav_to_4col_AE_Features_324a`。同時決定 RabbitMQ routing key 中段。 |
| `config_id`          | 對應某個啟用中的 `AnalysisConfig`。由該配置提供正式的分析參數。                  |
| `mongodb_instance`   | （可選）指定分析節點要連線的 MongoDB instance ID；預設為寫入資料的來源instance。   |

可視需要在 action 內加入自訂欄位（例如 `notes`），分析任務會完整收到該 JSON 以便 pipeline 取用。

---

## 4. 建立與維護規則

### 4.1 透過 Web UI

1. 登入後前往「路由規則」頁面（`core/state_management/views/routing_views.py`）。
2. 點擊「建立規則」，依表單提示輸入：
   - 優先級（整數）
   - `conditions` 與 `actions` JSON（建議先用外部工具驗證格式）
   - 啟用狀態
3. 儲存後即可在列表看到新規則；可隨時編輯、停用或刪除。

> 表單元件使用 `RoutingRuleForm`，若 JSON 格式錯誤會直接提示。

### 4.2 透過 API

`/api/routing` 暴露 REST 介面（`core/state_management/api/routing_api.py`）：

- `GET /api/routing?enabled_only=true`：查詢規則列表。
- `POST /api/routing`：以 JSON 建立規則。
- `PUT /api/routing/<rule_id>`：更新規則（不可修改 `rule_id`、`created_at`）。
- `POST /api/routing/test`：傳入 `info_features` 進行匹配測試。

可用於自動化部署或 CI 驗證。

---

## 5. 透過規則設定分析參數

1. 在「分析設定」建立或匯入所需的 `config_id`，於 `parameters` 欄填入 JSON，例如：
   ```json
   {
     "model_path": "gridfs://models/fan_v1.pth",
     "window_size": 2048,
     "hop_length": 512,
     "postprocess": {
       "smooth": true,
       "threshold": 0.65
     }
   }
   ```
2. 在路由規則的 `actions` 中引用該 `config_id`。調度器在 `_create_tasks_for_rule()`（`core/state_management/services/task_scheduler.py`）會把 `config_id` 與 `analysis_method_id` 寫進任務 payload。
3. 分析節點收到任務後依 `config_id` 從 `analysis_configs` 集合拉取參數，確保不同資料批次能套用不同設定。

---

## 6. 典型使用範例

以下規則示範如何處理來自 MiMII 與 CPC 的資料：

```json
{
  "rule_name": "MIMII Fan 自動分析",
  "priority": 90,
  "conditions": {
    "dataset_UUID": "mimii_batch_upload",
    "mimii_metadata.machine_type": ["fan"],
    "label": {"$in": ["normal", "abnormal"]}
  },
  "actions": [
    {
      "analysis_method_id": "fan_autoencoder_v2",
      "config_id": "fan_ae_v2_config",
      "mongodb_instance": "default"
    }
  ]
}
```

```json
{
  "rule_name": "CPC 測試資料走 QA 節點",
  "priority": 60,
  "conditions": {
    "dataset_UUID": "cpc_batch_upload",
    "info_features.testing": true
  },
  "actions": [
    {
      "analysis_method_id": "cpc_diagnosis_pipeline",
      "config_id": "cpc_diag_beta",
      "mongodb_instance": "qa-replica"
    },
    {
      "analysis_method_id": "cpc_signal_audit",
      "config_id": "cpc_audit_lite"
    }
  ]
}
```

當 batch_upload 寫入符合條件的紀錄時，調度器會分別建立 1 或 2 條任務並丟進 RabbitMQ，由訂閱 `analysis.fan_autoencoder_v2.#` 或 `analysis.cpc_diagnosis_pipeline.#` 的節點接手。

---

## 7. 測試與監控

- **規則測試 API**：在建立或修改規則後，呼叫 `POST /api/routing/test`，body 直接填入擬測的 `info_features` 即可取得命中規則列表。
- **TaskScheduler 日誌**：查看 `logs/state_management.log`（或實際設定的 log）內關鍵訊息，如「找到 X 個匹配規則」或「任務已發送」。
- **RabbitMQ 監控**：透過管理介面或 `rabbitmqctl list_queues` 監看 `analysis_tasks_queue` 堆積狀況。
- **分析節點日誌**：`a_sub_system/analysis_service_v2/logs/analysis_service.log` 會記錄任務接收與失敗重試。

---

## 8. 疑難排解

| 症狀                 | 檢查項                                                                                                |
| -------------------- | ----------------------------------------------------------------------------------------------------- |
| 新資料未觸發任務     | 確認 `TaskScheduler` 是否正在執行、MongoDB instance已啟用、`info_features.upload_time` 是否存在。 |
| 規則應命中卻沒有     | 使用 `/api/routing/test` 驗證條件是否與實際欄位名稱相符（大小寫、巢狀 key）。                       |
| 任務送出但節點未處理 | 檢查 RabbitMQ routing key 是否與分析節點綁定相符；確定分析節點設定的 `routing_key` 非過度限制。     |
| 分析參數無法套用     | 確認 `config_id` 是否啟用、JSON 格式正確且節點具備讀取 `analysis_configs` 所需權限。              |

---

## 9. 建議的作業流程

1. 由資料工程師確認 batch_upload 欄位完整。
2. 建立/更新 `AnalysisConfig`，將新模型與參數上線。
3. 在測試環境用 `/api/routing/test` 驗證規則。
4. 於 Web UI 啟用規則並觀察調度器及 RabbitMQ 日誌。
5. 分析節點驗收結果後，再推廣至正式環境。

依此流程，可確保資料自上傳到分析的路徑清晰可控，並能透過配置快速調整分析策略。
