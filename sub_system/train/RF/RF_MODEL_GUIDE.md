# éš¨æ©Ÿæ£®æ—åˆ†é¡å™¨è¨“ç·´èˆ‡éƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç›®éŒ„

1. [ç³»çµ±æ¦‚è¿°](#ç³»çµ±æ¦‚è¿°)
2. [ç’°å¢ƒæº–å‚™](#ç’°å¢ƒæº–å‚™)
3. [æ¨¡å‹è¨“ç·´](#æ¨¡å‹è¨“ç·´)
4. [æ¨¡å‹è©•ä¼°](#æ¨¡å‹è©•ä¼°)
5. [æ¨¡å‹éƒ¨ç½²](#æ¨¡å‹éƒ¨ç½²)
6. [é…ç½®èªªæ˜](#é…ç½®èªªæ˜)
7. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)

---

## ğŸ¯ ç³»çµ±æ¦‚è¿°

æœ¬ç³»çµ±æä¾›åŸºæ–¼éš¨æ©Ÿæ£®æ—(Random Forest)çš„éŸ³é »ç•°å¸¸æª¢æ¸¬åˆ†é¡å™¨,ç”¨æ–¼æ›¿æ›åŸæœ‰çš„éš¨æ©Ÿåˆ†é¡å™¨ã€‚

### å·¥ä½œæµç¨‹

```
1. æ‰¹é‡ä¸Šå‚³éŸ³é » (batch_upload) 
   â†“
2. åˆ†ææœå‹™è™•ç† (analysis_service)
   - Step 1: éŸ³è¨Šåˆ‡å‰²
   - Step 2: LEAF ç‰¹å¾µæå–
   - Step 3: éš¨æ©Ÿåˆ†é¡ (å¾…æ›¿æ›)
   â†“
3. è¨“ç·´ RF æ¨¡å‹ (train_rf_model.py)
   â†“
4. è©•ä¼°æ¨¡å‹æ•ˆèƒ½ (evaluate_model.py)
   â†“
5. éƒ¨ç½²æ¨¡å‹åˆ°åˆ†ææœå‹™
   - æ›´æ–°é…ç½®
   - æ›¿æ›åˆ†é¡å™¨
   â†“
6. ä½¿ç”¨ RF æ¨¡å‹é€²è¡Œå¯¦éš›åˆ†é¡
```

---

## ğŸ› ï¸ ç’°å¢ƒæº–å‚™

### 1. å®‰è£ä¾è³´å¥—ä»¶

```bash
pip install scikit-learn matplotlib seaborn --break-system-packages
```

### 2. æª¢æŸ¥å¿…è¦æª”æ¡ˆ

ç¢ºä¿ä»¥ä¸‹æª”æ¡ˆå­˜åœ¨:
- `train_rf_model.py` - è¨“ç·´è…³æœ¬
- `evaluate_model.py` - è©•ä¼°è…³æœ¬  
- `step3_classifier_updated.py` - æ›´æ–°çš„åˆ†é¡å™¨

### 3. æª¢æŸ¥ MongoDB è³‡æ–™

ç¢ºä¿ MongoDB ä¸­æœ‰è¶³å¤ çš„å·²æ¨™è¨˜è³‡æ–™:

```python
from pymongo import MongoClient

client = MongoClient("mongodb://web_ui:hod2iddfsgsrl@localhost:27020/admin")
db = client['web_db']
collection = db['recordings']

# æª¢æŸ¥è³‡æ–™æ•¸é‡
query = {
    'current_step': 4,
    'analysis_status': 'completed',
    'info_features.label': {'$exists': True, '$ne': 'unknown'}
}

count = collection.count_documents(query)
print(f"å¯ç”¨è¨“ç·´è³‡æ–™: {count} ç­†")

# æª¢æŸ¥æ¨™ç±¤åˆ†å¸ƒ
normal_count = collection.count_documents({**query, 'info_features.label': 'normal'})
abnormal_count = collection.count_documents({**query, 'info_features.label': 'abnormal'})

print(f"Normal: {normal_count} ç­†")
print(f"Abnormal: {abnormal_count} ç­†")
```

**å»ºè­°æœ€å°‘è³‡æ–™é‡:**
- Normal: 100+ ç­†
- Abnormal: 100+ ç­†
- ç¸½è¨ˆ: 200+ ç­†

---

## ğŸ“ æ¨¡å‹è¨“ç·´

### 1. åŸ·è¡Œè¨“ç·´è…³æœ¬

```bash
cd /path/to/project
python train_regrassion_model.py
```

### 2. è¨“ç·´éç¨‹

è¨“ç·´è…³æœ¬æœƒè‡ªå‹•å®Œæˆä»¥ä¸‹æ­¥é©Ÿ:

#### æ­¥é©Ÿ 1: è¼‰å…¥è¨“ç·´è³‡æ–™
- å¾ MongoDB è®€å–å·²å®Œæˆåˆ†æçš„è¨˜éŒ„
- æå– LEAF ç‰¹å¾µå’Œæ¨™ç±¤
- èšåˆå¤šå€‹åˆ‡ç‰‡çš„ç‰¹å¾µ (é è¨­ä½¿ç”¨å¹³å‡å€¼)

#### æ­¥é©Ÿ 2: æº–å‚™è¨“ç·´è³‡æ–™
- åˆ†å‰²è³‡æ–™é›†: è¨“ç·´é›†(70%) / é©—è­‰é›†(10%) / æ¸¬è©¦é›†(20%)
- æ¨™æº–åŒ–ç‰¹å¾µ
- ç·¨ç¢¼æ¨™ç±¤

#### æ­¥é©Ÿ 3: è¨“ç·´æ¨¡å‹
- ä½¿ç”¨éš¨æ©Ÿæ£®æ—æ¼”ç®—æ³•
- å¯é¸æ“‡ç¶²æ ¼æœå°‹æœ€ä½³åƒæ•¸
- åŸ·è¡Œäº¤å‰é©—è­‰

#### æ­¥é©Ÿ 4: è©•ä¼°æ¨¡å‹
- è¨ˆç®—æº–ç¢ºç‡ã€ç²¾ç¢ºç‡ã€å¬å›ç‡ã€F1åˆ†æ•¸
- ç”Ÿæˆæ··æ·†çŸ©é™£
- ç¹ªè£½ ROC æ›²ç·š
- åˆ†æç‰¹å¾µé‡è¦æ€§

#### æ­¥é©Ÿ 5: å„²å­˜æ¨¡å‹
- å„²å­˜æ¨¡å‹æª”æ¡ˆ (`rf_classifier.pkl`)
- å„²å­˜æ¨™æº–åŒ–å™¨ (`feature_scaler.pkl`)
- å„²å­˜å…ƒè³‡æ–™ (`model_metadata.json`)

#### æ­¥é©Ÿ 6: ç”Ÿæˆè¦–è¦ºåŒ–å ±å‘Š
- æ··æ·†çŸ©é™£åœ–
- ç‰¹å¾µé‡è¦æ€§åœ–
- ROC æ›²ç·šåœ–

### 3. è¼¸å‡ºæª”æ¡ˆ

è¨“ç·´å®Œæˆå¾Œæœƒç”Ÿæˆä»¥ä¸‹æª”æ¡ˆ:

```
models/
â”œâ”€â”€ rf_classifier.pkl      # è¨“ç·´å¥½çš„æ¨¡å‹
â”œâ”€â”€ feature_scaler.pkl     # ç‰¹å¾µæ¨™æº–åŒ–å™¨
â””â”€â”€ model_metadata.json    # æ¨¡å‹å…ƒè³‡æ–™

training_reports/
â”œâ”€â”€ confusion_matrix.png       # æ··æ·†çŸ©é™£
â”œâ”€â”€ feature_importance.png     # ç‰¹å¾µé‡è¦æ€§
â”œâ”€â”€ roc_curve.png             # ROC æ›²ç·š
â””â”€â”€ evaluation_report.json    # è©•ä¼°å ±å‘Š
```

### 4. æª¢è¦–è¨“ç·´çµæœ

```bash
# æŸ¥çœ‹è©•ä¼°å ±å‘Š
cat training_reports/evaluation_report.json

# æŸ¥çœ‹æ¨¡å‹å…ƒè³‡æ–™
cat models/model_metadata.json

# æŸ¥çœ‹åœ–è¡¨ (éœ€è¦åœ–ç‰‡æª¢è¦–å™¨)
# Windows: start training_reports/confusion_matrix.png
# Linux: xdg-open training_reports/confusion_matrix.png
```

---

## ğŸ“Š æ¨¡å‹è©•ä¼°

### 1. åŸ·è¡Œè©•ä¼°è…³æœ¬

```bash
python regrassion_evaluate_model.py
```

### 2. è©•ä¼°æ¨¡å¼

#### æ¨¡å¼ 1: è·¨è³‡æ–™é›†è©•ä¼°
- å¾ MongoDB è¼‰å…¥æ‰€æœ‰å¯ç”¨è³‡æ–™
- è©•ä¼°æ¨¡å‹åœ¨å®Œæ•´è³‡æ–™é›†ä¸Šçš„æ•ˆèƒ½
- ç”Ÿæˆæ–°çš„è©•ä¼°å ±å‘Šå’Œè¦–è¦ºåŒ–

```
é¸æ“‡è©•ä¼°æ¨¡å¼:
  1. è·¨è³‡æ–™é›†è©•ä¼°ï¼ˆå¾ MongoDB è¼‰å…¥æ‰€æœ‰è³‡æ–™ï¼‰
  2. å–®ä¸€è¨˜éŒ„é æ¸¬æ¸¬è©¦
  3. é¡¯ç¤ºæ¨¡å‹è©³ç´°è³‡è¨Š

è«‹è¼¸å…¥é¸é … (1, 2 æˆ– 3): 1
```

#### æ¨¡å¼ 2: å–®ä¸€è¨˜éŒ„é æ¸¬æ¸¬è©¦
- æ¸¬è©¦æ¨¡å‹å°å–®ä¸€è¨˜éŒ„çš„é æ¸¬
- å¯ç”¨æ–¼èª¿è©¦å’Œé©—è­‰

```
è«‹è¼¸å…¥é¸é … (1, 2 æˆ– 3): 2
è«‹è¼¸å…¥è¨˜éŒ„çš„ AnalyzeUUID: 501a3f22-d326-486e-9550-67feeb898ea0
```

#### æ¨¡å¼ 3: é¡¯ç¤ºæ¨¡å‹è©³ç´°è³‡è¨Š
- æŸ¥çœ‹æ¨¡å‹åƒæ•¸
- æŸ¥çœ‹è¨“ç·´æ­·å²
- æŸ¥çœ‹ç‰¹å¾µé‡è¦æ€§

### 3. è©•ä¼°æŒ‡æ¨™èªªæ˜

- **æº–ç¢ºç‡ (Accuracy)**: é æ¸¬æ­£ç¢ºçš„æ¯”ä¾‹
- **ç²¾ç¢ºç‡ (Precision)**: é æ¸¬ç‚ºç•°å¸¸çš„æ¨£æœ¬ä¸­çœŸæ­£ç•°å¸¸çš„æ¯”ä¾‹
- **å¬å›ç‡ (Recall)**: å¯¦éš›ç•°å¸¸æ¨£æœ¬ä¸­è¢«æ­£ç¢ºé æ¸¬çš„æ¯”ä¾‹
- **F1åˆ†æ•¸**: ç²¾ç¢ºç‡å’Œå¬å›ç‡çš„èª¿å’Œå¹³å‡
- **ROC-AUC**: ROC æ›²ç·šä¸‹é¢ç©,è¶Šæ¥è¿‘ 1 è¶Šå¥½

### 4. æ··æ·†çŸ©é™£è§£è®€

```
              é æ¸¬ Normal  é æ¸¬ Abnormal
å¯¦éš› Normal       TP_n          FP_a
å¯¦éš› Abnormal     FN_a          TP_a
```

- **TP (True Positive)**: æ­£ç¢ºé æ¸¬ç‚ºç•°å¸¸
- **TN (True Negative)**: æ­£ç¢ºé æ¸¬ç‚ºæ­£å¸¸
- **FP (False Positive)**: èª¤å ± (æ­£å¸¸é æ¸¬ç‚ºç•°å¸¸)
- **FN (False Negative)**: æ¼å ± (ç•°å¸¸é æ¸¬ç‚ºæ­£å¸¸)

**ç†æƒ³æƒ…æ³**: å°è§’ç·šæ•¸å­—å¤§,éå°è§’ç·šæ•¸å­—å°

---

## ğŸš€ æ¨¡å‹éƒ¨ç½²

### 1. æ›´æ–°åˆ†ææœå‹™é…ç½®

ç·¨è¼¯ `a_sub_system/analysis_service/config.py`:

```python
# ==================== åˆ†é¡é…ç½® ====================
CLASSIFICATION_CONFIG = {
    'method': 'rf_model',  # æ”¹ç‚º 'rf_model'
    'classes': ['normal', 'abnormal'],
    
    # æ¨¡å‹è·¯å¾‘ (ä½¿ç”¨çµ•å°è·¯å¾‘)
    'model_path': '/path/to/project/models',  # ä¿®æ”¹ç‚ºå¯¦éš›è·¯å¾‘
    'threshold': 0.5
}
```

### 2. æ›¿æ›åˆ†é¡å™¨æª”æ¡ˆ

```bash
# å‚™ä»½åŸå§‹åˆ†é¡å™¨
cp a_sub_system/analysis_service/processors/step3_classifier.py \
   a_sub_system/analysis_service/processors/step3_classifier_backup.py

# ä½¿ç”¨æ–°åˆ†é¡å™¨
cp step3_classifier_updated.py \
   a_sub_system/analysis_service/processors/step3_classifier.py
```

### 3. é‡å•Ÿåˆ†ææœå‹™

```bash
cd a_sub_system/analysis_service
python main.py
```

### 4. é©—è­‰éƒ¨ç½²

ä¸Šå‚³ä¸€å€‹æ¸¬è©¦éŸ³é »ä¸¦æª¢æŸ¥çµæœ:

```python
from pymongo import MongoClient

client = MongoClient("mongodb://web_ui:hod2iddfsgsrl@localhost:27020/admin")
db = client['web_db']
collection = db['recordings']

# æŸ¥è©¢æœ€æ–°è¨˜éŒ„
latest = collection.find_one(
    {'current_step': 4, 'analysis_status': 'completed'},
    sort=[('created_at', -1)]
)

# æª¢æŸ¥åˆ†é¡çµæœ
classification = latest['analyze_features'][2]  # Step 3 çµæœ
print(f"æ–¹æ³•: {classification['classification_results']['method']}")
print(f"é æ¸¬: {classification['classification_results']['summary']['final_prediction']}")
```

**é æœŸçµæœ**: `method` æ‡‰è©²æ˜¯ `'rf_model'`

---

## âš™ï¸ é…ç½®èªªæ˜

### è¨“ç·´é…ç½® (train_rf_model.py)

#### ç‰¹å¾µé…ç½®

```python
FEATURE_CONFIG = {
    'feature_dim': 40,           # LEAF ç‰¹å¾µç¶­åº¦
    'normalize': True,           # æ˜¯å¦æ¨™æº–åŒ–
    'aggregation': 'mean'        # èšåˆæ–¹å¼: mean, max, median, all
}
```

**èšåˆæ–¹å¼èªªæ˜:**
- `mean`: å–æ‰€æœ‰åˆ‡ç‰‡ç‰¹å¾µçš„å¹³å‡å€¼ (æ¨è–¦)
- `max`: å–æœ€å¤§å€¼
- `median`: å–ä¸­ä½æ•¸
- `all`: ä½¿ç”¨å¤šç¨®çµ±è¨ˆé‡ (mean + std + max + min)

#### æ¨¡å‹é…ç½®

```python
MODEL_CONFIG = {
    'rf_params': {
        'n_estimators': 100,         # æ¨¹çš„æ•¸é‡
        'max_depth': None,           # æ¨¹çš„æœ€å¤§æ·±åº¦
        'min_samples_split': 2,      # åˆ†è£‚æ‰€éœ€æœ€å°æ¨£æœ¬æ•¸
        'min_samples_leaf': 1,       # è‘‰ç¯€é»æœ€å°æ¨£æœ¬æ•¸
        'max_features': 'sqrt',      # æ¯æ¬¡åˆ†è£‚è€ƒæ…®çš„ç‰¹å¾µæ•¸
        'class_weight': 'balanced'   # è™•ç†é¡åˆ¥ä¸å¹³è¡¡
    },
    
    'grid_search': False,            # æ˜¯å¦ä½¿ç”¨ç¶²æ ¼æœå°‹
}
```

**åƒæ•¸èª¿æ•´å»ºè­°:**
- å¦‚æœ**éæ“¬åˆ**: æ¸›å°‘ `n_estimators` æˆ–è¨­å®š `max_depth`
- å¦‚æœ**æ¬ æ“¬åˆ**: å¢åŠ  `n_estimators` æˆ–æ¸›å° `min_samples_split`
- å¦‚æœ**é¡åˆ¥ä¸å¹³è¡¡**: ä¿æŒ `class_weight='balanced'`

#### è¨“ç·´é…ç½®

```python
TRAINING_CONFIG = {
    'test_size': 0.2,              # æ¸¬è©¦é›†æ¯”ä¾‹
    'val_size': 0.1,               # é©—è­‰é›†æ¯”ä¾‹
    'cross_validation': True,      # æ˜¯å¦äº¤å‰é©—è­‰
    'cv_folds': 5,                 # äº¤å‰é©—è­‰æŠ˜æ•¸
}
```

### éƒ¨ç½²é…ç½® (config.py)

```python
CLASSIFICATION_CONFIG = {
    'method': 'rf_model',          # åˆ†é¡æ–¹æ³•: 'random' æˆ– 'rf_model'
    'model_path': '/path/to/models',  # æ¨¡å‹ç›®éŒ„è·¯å¾‘
    'threshold': 0.5,              # åˆ†é¡é–¾å€¼
}
```

---

## â“ å¸¸è¦‹å•é¡Œ

### Q1: è¨“ç·´æ™‚å‡ºç¾ "æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„è¨“ç·´è³‡æ–™"

**åŸå› **: MongoDB ä¸­æ²’æœ‰è¶³å¤ çš„å·²å®Œæˆåˆ†æä¸”æœ‰æ¨™ç±¤çš„è¨˜éŒ„

**è§£æ±ºæ–¹æ³•**:
1. æª¢æŸ¥è³‡æ–™æ•¸é‡:
```python
collection.count_documents({
    'current_step': 4,
    'analysis_status': 'completed',
    'info_features.label': {'$exists': True, '$ne': 'unknown'}
})
```

2. ä½¿ç”¨ batch_upload å·¥å…·ä¸Šå‚³æ›´å¤šå·²æ¨™è¨˜çš„éŸ³é »è³‡æ–™

### Q2: æ¨¡å‹æº–ç¢ºç‡å¾ˆä½ (<70%)

**å¯èƒ½åŸå› **:
- è¨“ç·´è³‡æ–™ä¸è¶³
- è³‡æ–™å“è³ªä¸ä½³
- ç‰¹å¾µèšåˆæ–¹å¼ä¸é©åˆ
- é¡åˆ¥åš´é‡ä¸å¹³è¡¡

**è§£æ±ºæ–¹æ³•**:
1. å¢åŠ è¨“ç·´è³‡æ–™é‡ (å»ºè­° 500+ ç­†)
2. æª¢æŸ¥è³‡æ–™æ¨™ç±¤æ˜¯å¦æ­£ç¢º
3. å˜—è©¦ä¸åŒçš„èšåˆæ–¹å¼ (`aggregation` åƒæ•¸)
4. èª¿æ•´æ¨¡å‹åƒæ•¸æˆ–ä½¿ç”¨ç¶²æ ¼æœå°‹

### Q3: éƒ¨ç½²å¾Œåˆ†ææœå‹™ä»ä½¿ç”¨éš¨æ©Ÿåˆ†é¡

**æª¢æŸ¥æ¸…å–®**:
1. ç¢ºèª `config.py` ä¸­ `method='rf_model'`
2. ç¢ºèª `model_path` æŒ‡å‘æ­£ç¢ºçš„ç›®éŒ„
3. ç¢ºèªæ¨¡å‹æª”æ¡ˆå­˜åœ¨:
   - `models/rf_classifier.pkl`
   - `models/feature_scaler.pkl`
   - `models/model_metadata.json`
4. æª¢æŸ¥åˆ†ææœå‹™æ—¥èªŒæ˜¯å¦æœ‰è¼‰å…¥éŒ¯èª¤
5. ç¢ºèªå·²é‡å•Ÿåˆ†ææœå‹™

### Q4: è¨˜æ†¶é«”ä¸è¶³éŒ¯èª¤

**è§£æ±ºæ–¹æ³•**:
1. æ¸›å°‘ `n_estimators` (ä¾‹å¦‚æ”¹ç‚º 50)
2. è¨­å®š `max_depth` é™åˆ¶æ¨¹çš„æ·±åº¦
3. æ¸›å°‘ä¸¦è¡Œè™•ç†æ•¸é‡ (`n_jobs`)
4. åˆ†æ‰¹è™•ç†è³‡æ–™

### Q5: å¦‚ä½•æ”¹å–„æ¨¡å‹æ•ˆèƒ½?

**ç­–ç•¥**:
1. **å¢åŠ è³‡æ–™é‡**: æ›´å¤šè¨“ç·´è³‡æ–™é€šå¸¸èƒ½æ”¹å–„æ•ˆèƒ½
2. **å¹³è¡¡è³‡æ–™é›†**: ç¢ºä¿ normal å’Œ abnormal æ¨£æœ¬æ•¸é‡æ¥è¿‘
3. **ç‰¹å¾µå·¥ç¨‹**: å˜—è©¦ä¸åŒçš„èšåˆæ–¹å¼
4. **è¶…åƒæ•¸èª¿æ•´**: ä½¿ç”¨ç¶²æ ¼æœå°‹å°‹æ‰¾æœ€ä½³åƒæ•¸
5. **é›†æˆå­¸ç¿’**: è€ƒæ…®ä½¿ç”¨ XGBoost æˆ–å…¶ä»–é€²éšæ¼”ç®—æ³•

### Q6: å¦‚ä½•å›é€€åˆ°éš¨æ©Ÿåˆ†é¡å™¨?

```python
# 1. ä¿®æ”¹é…ç½®
CLASSIFICATION_CONFIG = {
    'method': 'random',  # æ”¹å› 'random'
    ...
}

# 2. æ¢å¾©åŸå§‹åˆ†é¡å™¨ (å¦‚æœæœ‰å‚™ä»½)
cp a_sub_system/analysis_service/processors/step3_classifier_backup.py \
   a_sub_system/analysis_service/processors/step3_classifier.py

# 3. é‡å•Ÿåˆ†ææœå‹™
```

---

## ğŸ“ ä½¿ç”¨ç¯„ä¾‹

### å®Œæ•´å·¥ä½œæµç¨‹ç¯„ä¾‹

```bash
# 1. ä¸Šå‚³è¨“ç·´è³‡æ–™ (å‡è¨­å·²æœ‰æ¨™è¨˜çš„è³‡æ–™é›†)
cd a_sub_system/batch_upload
python batch_upload.py  # ä¸Šå‚³ normal å’Œ abnormal è³‡æ–™

# 2. ç­‰å¾…åˆ†ææœå‹™è™•ç†å®Œæˆ
cd ../analysis_service
python main.py

# 3. è¨“ç·´æ¨¡å‹
cd ../../
python train_regrassion_model.py

# 4. è©•ä¼°æ¨¡å‹
python regrassion_evaluate_model.py
# é¸æ“‡é¸é … 1 é€²è¡Œè·¨è³‡æ–™é›†è©•ä¼°

# 5. å¦‚æœæ•ˆèƒ½æ»¿æ„,éƒ¨ç½²æ¨¡å‹
# ç·¨è¼¯ a_sub_system/analysis_service/config.py
# æ›¿æ›åˆ†é¡å™¨æª”æ¡ˆ
# é‡å•Ÿåˆ†ææœå‹™

# 6. æ¸¬è©¦æ–°æ¨¡å‹
python regrassion_evaluate_model.py
# é¸æ“‡é¸é … 2 æ¸¬è©¦å–®ä¸€è¨˜éŒ„
```

### Python API ä½¿ç”¨ç¯„ä¾‹

```python
# è¼‰å…¥æ¨¡å‹é€²è¡Œé æ¸¬
from evaluate_model import ModelEvaluator
import numpy as np

# åˆå§‹åŒ–è©•ä¼°å™¨
evaluator = ModelEvaluator('models')

# æº–å‚™ç‰¹å¾µ (40 ç¶­)
features = np.random.randn(1, 40)

# é æ¸¬
prediction = evaluator.model.predict(features)
proba = evaluator.model.predict_proba(features)

print(f"é æ¸¬é¡åˆ¥: {prediction[0]}")  # 0=normal, 1=abnormal
print(f"é æ¸¬æ©Ÿç‡: Normal={proba[0][0]:.3f}, Abnormal={proba[0][1]:.3f}")
```

---

## ğŸ“š åƒè€ƒè³‡æ–™

- [Scikit-learn Random Forest æ–‡ä»¶](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- [LEAF ç‰¹å¾µæå–è«–æ–‡](https://arxiv.org/abs/2101.08596)
- [ç•°å¸¸æª¢æ¸¬æœ€ä½³å¯¦è¸](https://scikit-learn.org/stable/modules/outlier_detection.html)

---

## ğŸ”„ æ›´æ–°æ­·å²

- **v1.0** (2025-10-03): åˆå§‹ç‰ˆæœ¬
  - éš¨æ©Ÿæ£®æ—åˆ†é¡å™¨å¯¦ä½œ
  - å®Œæ•´è¨“ç·´èˆ‡è©•ä¼°æµç¨‹
  - éƒ¨ç½²æŒ‡å—

---

## ğŸ“§ æ”¯æ´

å¦‚æœ‰å•é¡Œæˆ–å»ºè­°,è«‹å»ºç«‹ Issue æˆ–è¯ç¹«é–‹ç™¼åœ˜éšŠã€‚
